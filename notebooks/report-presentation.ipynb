{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Deepfake Detection — Report & Presentation\n",
        "\n",
        "Summary of the project: datasets, methodology, results, and conclusions. Suitable for reports and presentations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Introduction & Objectives\n",
        "\n",
        "- **Goal**: Detect synthetic (deepfake) speech vs human (real) speech from audio.\n",
        "- **Approach**: Handcrafted acoustic features (MFCC, spectral, pitch, etc.) + classical ML (SVM, XGBoost, Random Forest, Decision Tree, Logistic Regression).\n",
        "- **Evaluation**: In-dataset (FoR test) and zero-shot (In-the-Wild, ElevenLabs) to assess generalisation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Samples</th>\n",
              "      <th>Real</th>\n",
              "      <th>Fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FoR train</td>\n",
              "      <td>53868</td>\n",
              "      <td>26941</td>\n",
              "      <td>26927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FoR val</td>\n",
              "      <td>10798</td>\n",
              "      <td>5400</td>\n",
              "      <td>5398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FoR test</td>\n",
              "      <td>4634</td>\n",
              "      <td>2264</td>\n",
              "      <td>2370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ITW</td>\n",
              "      <td>31779</td>\n",
              "      <td>19963</td>\n",
              "      <td>11816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ElevenLabs</td>\n",
              "      <td>136</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Dataset  Samples   Real   Fake\n",
              "0   FoR train    53868  26941  26927\n",
              "1     FoR val    10798   5400   5398\n",
              "2    FoR test     4634   2264   2370\n",
              "3         ITW    31779  19963  11816\n",
              "4  ElevenLabs      136     74     62"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "from configs.config import FEATURES_DIR, ITW_DATASET_PATH, ELEVEN_LABS_FEATURES_PATH, MODELS_PATH, FINAL_MODELS_PATH\n",
        "\n",
        "FEATURE_SET = \"mean_20_128_256_128\"\n",
        "paths = {\n",
        "    \"FoR train\": os.path.join(FEATURES_DIR, f\"training_features_{FEATURE_SET}.parquet\"),\n",
        "    \"FoR val\": os.path.join(FEATURES_DIR, f\"validation_features_{FEATURE_SET}.parquet\"),\n",
        "    \"FoR test\": os.path.join(FEATURES_DIR, f\"testing_features_{FEATURE_SET}.parquet\"),\n",
        "    \"ITW\": os.path.join(ITW_DATASET_PATH, \"normalized_features\", f\"itw_features_{FEATURE_SET}_trimmed_loudness_normalized.parquet\"),\n",
        "    \"ElevenLabs\": os.path.join(ELEVEN_LABS_FEATURES_PATH, f\"eleven_labs_features_{FEATURE_SET}.parquet\"),\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, p in paths.items():\n",
        "    if os.path.isfile(p):\n",
        "        df = pd.read_parquet(p)\n",
        "        n_real = (df[\"label\"] == \"real\").sum() if \"label\" in df.columns else \"—\"\n",
        "        n_fake = (df[\"label\"] == \"fake\").sum() if \"label\" in df.columns else \"—\"\n",
        "        rows.append({\"Dataset\": name, \"Samples\": len(df), \"Real\": n_real, \"Fake\": n_fake})\n",
        "    else:\n",
        "        rows.append({\"Dataset\": name, \"Samples\": \"—\", \"Real\": \"—\", \"Fake\": \"—\"})\n",
        "\n",
        "dataset_table = pd.DataFrame(rows)\n",
        "display(dataset_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **FoR (Forensics in the Wild)**: train/validation/test splits; primary training and in-dataset evaluation.\n",
        "- **In-the-Wild**: external benchmark; zero-shot evaluation only.\n",
        "- **ElevenLabs**: external benchmark; zero-shot evaluation only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Methodology\n",
        "\n",
        "- **Features**: MFCC (20) + deltas, spectral (centroid, bandwidth, flatness, rolloff), RMSE, ZCR, pitch (YIN), mel spectrogram; aggregated per file (mean).\n",
        "- **Models**: Linear SVM, RBF SVM, Logistic Regression, Random Forest, XGBoost, Decision Tree (see notebooks in this folder).\n",
        "- **Training**: FoR train (and validation where used); StandardScaler + classifier; class_weight=\"balanced\" for SVMs.\n",
        "- **Evaluation**: Accuracy, precision, recall, F1 (macro), ROC AUC; confusion matrices; zero-shot on ITW and ElevenLabs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Results — FoR test set\n",
        "\n",
        "Summary of saved experiments (when available). Metrics are read from `notebooks/experiments/<model>/<exp>/metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Experiment</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_f1_macro</th>\n",
              "      <th>val_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dtree</td>\n",
              "      <td>exp_20260207_210558</td>\n",
              "      <td>0.9545</td>\n",
              "      <td>0.9565</td>\n",
              "      <td>0.9538</td>\n",
              "      <td>0.9543</td>\n",
              "      <td>0.9588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>linear_svm</td>\n",
              "      <td>exp_20260207_193304</td>\n",
              "      <td>0.7052</td>\n",
              "      <td>0.7741</td>\n",
              "      <td>0.6993</td>\n",
              "      <td>0.6815</td>\n",
              "      <td>0.8904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logistic_reg</td>\n",
              "      <td>exp_20260207_192945</td>\n",
              "      <td>0.7279</td>\n",
              "      <td>0.7875</td>\n",
              "      <td>0.7226</td>\n",
              "      <td>0.7099</td>\n",
              "      <td>0.9022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>poly_svm</td>\n",
              "      <td>exp_20260207_201742</td>\n",
              "      <td>0.7615</td>\n",
              "      <td>0.8002</td>\n",
              "      <td>0.7656</td>\n",
              "      <td>0.7554</td>\n",
              "      <td>0.8479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rbf_svm</td>\n",
              "      <td>exp_20260207_200752</td>\n",
              "      <td>0.7611</td>\n",
              "      <td>0.7614</td>\n",
              "      <td>0.7605</td>\n",
              "      <td>0.7607</td>\n",
              "      <td>0.8323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sigmoid_svm</td>\n",
              "      <td>exp_20260207_204305</td>\n",
              "      <td>0.7268</td>\n",
              "      <td>0.7656</td>\n",
              "      <td>0.7223</td>\n",
              "      <td>0.7137</td>\n",
              "      <td>0.8350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model           Experiment  val_accuracy  val_precision  val_recall  \\\n",
              "0         Dtree  exp_20260207_210558        0.9545         0.9565      0.9538   \n",
              "1    linear_svm  exp_20260207_193304        0.7052         0.7741      0.6993   \n",
              "2  logistic_reg  exp_20260207_192945        0.7279         0.7875      0.7226   \n",
              "3      poly_svm  exp_20260207_201742        0.7615         0.8002      0.7656   \n",
              "4       rbf_svm  exp_20260207_200752        0.7611         0.7614      0.7605   \n",
              "5   sigmoid_svm  exp_20260207_204305        0.7268         0.7656      0.7223   \n",
              "\n",
              "   val_f1_macro  val_roc_auc  \n",
              "0        0.9543       0.9588  \n",
              "1        0.6815       0.8904  \n",
              "2        0.7099       0.9022  \n",
              "3        0.7554       0.8479  \n",
              "4        0.7607       0.8323  \n",
              "5        0.7137       0.8350  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def collect_val_results(root_dir):\n",
        "    results = []\n",
        "    if not os.path.isdir(root_dir):\n",
        "        return results\n",
        "    for model_name in os.listdir(root_dir):\n",
        "        model_dir = os.path.join(root_dir, model_name)\n",
        "        if not os.path.isdir(model_dir):\n",
        "            continue\n",
        "        for exp_name in sorted(os.listdir(model_dir)):\n",
        "            exp_dir = os.path.join(model_dir, exp_name)\n",
        "            val_path = os.path.join(exp_dir, \"val_results.json\")\n",
        "            if not os.path.isfile(val_path):\n",
        "                continue\n",
        "            with open(val_path) as f:\n",
        "                val_entries = json.load(f)\n",
        "            if not isinstance(val_entries, list) or not val_entries:\n",
        "                continue\n",
        "            best = max(val_entries, key=lambda e: e.get(\"selection_score\", 0))\n",
        "            row = {\"Model\": model_name, \"Experiment\": exp_name}\n",
        "            for k in [\"val_accuracy\", \"val_precision\", \"val_recall\", \"val_f1_macro\", \"val_roc_auc\"]:\n",
        "                v = best.get(k)\n",
        "                if v is not None:\n",
        "                    row[k] = round(v[0] if isinstance(v, (list, tuple)) else v, 4)\n",
        "            results.append(row)\n",
        "    return results\n",
        "\n",
        "val_results = collect_val_results(FINAL_MODELS_PATH)\n",
        "if val_results:\n",
        "    val_df = pd.DataFrame(val_results)\n",
        "    display(val_df)\n",
        "else:\n",
        "    print(\"No saved experiments found under FINAL_MODELS_PATH.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Results — ITW test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Experiment</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dtree</td>\n",
              "      <td>exp_20260207_210558</td>\n",
              "      <td>0.5905</td>\n",
              "      <td>0.5495</td>\n",
              "      <td>0.5451</td>\n",
              "      <td>0.5446</td>\n",
              "      <td>0.5216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>linear_svm</td>\n",
              "      <td>exp_20260207_193304</td>\n",
              "      <td>0.7200</td>\n",
              "      <td>0.7075</td>\n",
              "      <td>0.7181</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>0.7811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logistic_reg</td>\n",
              "      <td>exp_20260207_192945</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.7179</td>\n",
              "      <td>0.7073</td>\n",
              "      <td>0.7775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>poly_svm</td>\n",
              "      <td>exp_20260207_201742</td>\n",
              "      <td>0.6742</td>\n",
              "      <td>0.6497</td>\n",
              "      <td>0.6140</td>\n",
              "      <td>0.6144</td>\n",
              "      <td>0.6907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rbf_svm</td>\n",
              "      <td>exp_20260207_200752</td>\n",
              "      <td>0.7059</td>\n",
              "      <td>0.6968</td>\n",
              "      <td>0.7086</td>\n",
              "      <td>0.6974</td>\n",
              "      <td>0.7631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sigmoid_svm</td>\n",
              "      <td>exp_20260207_204305</td>\n",
              "      <td>0.6601</td>\n",
              "      <td>0.6768</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.6585</td>\n",
              "      <td>0.7038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Model           Experiment  accuracy  precision  recall      f1  \\\n",
              "0         Dtree  exp_20260207_210558    0.5905     0.5495  0.5451  0.5446   \n",
              "1    linear_svm  exp_20260207_193304    0.7200     0.7075  0.7181  0.7097   \n",
              "2  logistic_reg  exp_20260207_192945    0.7163     0.7060  0.7179  0.7073   \n",
              "3      poly_svm  exp_20260207_201742    0.6742     0.6497  0.6140  0.6144   \n",
              "4       rbf_svm  exp_20260207_200752    0.7059     0.6968  0.7086  0.6974   \n",
              "5   sigmoid_svm  exp_20260207_204305    0.6601     0.6768  0.6864  0.6585   \n",
              "\n",
              "   roc_auc  \n",
              "0   0.5216  \n",
              "1   0.7811  \n",
              "2   0.7775  \n",
              "3   0.6907  \n",
              "4   0.7631  \n",
              "5   0.7038  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def collect_experiment_metrics(root_dir):\n",
        "    results = []\n",
        "    if not os.path.isdir(root_dir):\n",
        "        return results\n",
        "    for model_name in os.listdir(root_dir):\n",
        "        model_dir = os.path.join(root_dir, model_name)\n",
        "        if not os.path.isdir(model_dir):\n",
        "            continue\n",
        "        for exp_name in sorted(os.listdir(model_dir)):\n",
        "            exp_dir = os.path.join(model_dir, exp_name)\n",
        "            metrics_path = os.path.join(exp_dir, \"metrics.json\")\n",
        "            if not os.path.isfile(metrics_path):\n",
        "                continue\n",
        "            with open(metrics_path) as f:\n",
        "                metrics = json.load(f)\n",
        "            row = {\"Model\": model_name, \"Experiment\": exp_name}\n",
        "            for k in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]:\n",
        "                if k in metrics:\n",
        "                    row[k] = round(metrics[k], 4)\n",
        "            results.append(row)\n",
        "    return results\n",
        "\n",
        "all_results = collect_experiment_metrics(FINAL_MODELS_PATH)\n",
        "if all_results:\n",
        "    metrics_df = pd.DataFrame(all_results)\n",
        "    display(metrics_df)\n",
        "else:\n",
        "    print(\"No saved experiments found under MODELS_PATH. Run experimental-pipeline-e2e.ipynb or the model notebooks and save experiments to populate this table.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Zero-shot evaluation\n",
        "\n",
        "Models trained on FoR are evaluated on **In-the-Wild** and **ElevenLabs** without retraining. See `model_zero_shot_evaluation.ipynb` for detailed per-model results and threshold analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Conclusions & reproducibility\n",
        "\n",
        "- **Summary**: Classical ML on handcrafted acoustic features achieves strong in-dataset performance on FoR; zero-shot performance on ITW and ElevenLabs reflects domain shift.\n",
        "- **Reproducibility**: Use `experimental-pipeline-e2e.ipynb` for a single end-to-end run (feature paths → train → evaluate → zero-shot → save). Ensure parquet feature files and (optionally) raw WAV are available as in README Data Setup."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
