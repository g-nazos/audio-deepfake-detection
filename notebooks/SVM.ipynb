{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43a3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import platform\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_linear_svm(\n",
    "    train_path: str,\n",
    "    test_path: str,\n",
    "    svc_params: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a Linear SVM on extracted audio features and evaluate on a test set.\n",
    "\n",
    "    Returns everything needed to save an experiment:\n",
    "    - trained pipeline\n",
    "    - evaluation metrics\n",
    "    - model parameters\n",
    "    - feature names\n",
    "    - extra metadata (train/test size)\n",
    "    \"\"\"\n",
    "\n",
    "    if svc_params is None:\n",
    "        svc_params = {\n",
    "            \"C\": 1.0,\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"max_iter\": 20000,\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "\n",
    "    train_df = pd.read_parquet(train_path)\n",
    "    train_df.dropna(inplace=True)\n",
    "    test_df = pd.read_parquet(test_path)\n",
    "    test_df.dropna(inplace=True)\n",
    "\n",
    "    # Split features and labels\n",
    "    def split_xy(df):\n",
    "        X = df.drop(columns=[\"label\", \"filename\"], errors=\"ignore\")\n",
    "        y = df[\"label\"].map({\"real\": 0, \"fake\": 1}).values\n",
    "        return X.values, y, X.columns.tolist()\n",
    "\n",
    "    X_train, y_train, feature_names = split_xy(train_df)\n",
    "    X_test, y_test, _ = split_xy(test_df)\n",
    "\n",
    "    # Build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", LinearSVC(**svc_params)),\n",
    "    ])\n",
    "\n",
    "    # Train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    }\n",
    "\n",
    "    # Extra metadata for saving\n",
    "    metadata_extra = {\n",
    "        \"train_samples\": X_train.shape[0],\n",
    "        \"test_samples\": X_test.shape[0],\n",
    "    }\n",
    "\n",
    "    return pipeline, metrics, svc_params, feature_names, metadata_extra\n",
    "\n",
    "\n",
    "\n",
    "def save_experiment(\n",
    "    model,\n",
    "    metrics: dict,\n",
    "    experiment_dir: str = \"experiments\",\n",
    "    experiment_name: str | None = None,\n",
    "    model_params: dict | None = None,\n",
    "    feature_names: list | None = None,\n",
    "    metadata_extra: dict | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save a trained model, evaluation metrics, model parameters, and metadata\n",
    "    to a structured experiment folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : any\n",
    "        Trained model object (e.g., sklearn pipeline, XGBoost model).\n",
    "\n",
    "    metrics : dict\n",
    "        Dictionary containing evaluation metrics.\n",
    "\n",
    "    experiment_dir : str\n",
    "        Root directory to store experiments.\n",
    "\n",
    "    experiment_name : str, optional\n",
    "        Name of the experiment folder. Auto-generated if None.\n",
    "\n",
    "    model_params : dict, optional\n",
    "        Dictionary of model hyperparameters.\n",
    "\n",
    "    feature_names : list of str, optional\n",
    "        List of feature names used in training.\n",
    "\n",
    "    metadata_extra : dict, optional\n",
    "        Additional metadata to save (dataset info, notes, etc.).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    exp_path : str\n",
    "        Path to the saved experiment folder.\n",
    "    \"\"\"\n",
    "    # Create experiment folder\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "    if experiment_name is None:\n",
    "        experiment_name = f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    exp_path = os.path.join(experiment_dir, experiment_name)\n",
    "    os.makedirs(exp_path, exist_ok=True)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(exp_path, \"model.joblib\"))\n",
    "\n",
    "    # Save metrics\n",
    "    with open(os.path.join(exp_path, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "    # Save model parameters\n",
    "    if model_params is not None:\n",
    "        with open(os.path.join(exp_path, \"model_params.json\"), \"w\") as f:\n",
    "            json.dump(model_params, f, indent=4)\n",
    "\n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"num_features\": len(feature_names) if feature_names is not None else None,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"python_version\": platform.python_version(),\n",
    "        \"platform\": platform.platform(),\n",
    "    }\n",
    "\n",
    "    if metadata_extra:\n",
    "        metadata.update(metadata_extra)\n",
    "\n",
    "    with open(os.path.join(exp_path, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "    print(f\"Experiment saved to: {exp_path}\")\n",
    "    return exp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aefb30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"c:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\training_features.parquet\"\n",
    "test_data_path= r\"c:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\testing_features.parquet\"\n",
    "svc_params = {\n",
    "            \"C\": 1.0,\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"max_iter\": 20000,\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "pipeline, metrics, svc_params, feature_names, metadata_extra = train_and_evaluate_linear_svm(train_data_path, test_data_path, svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece20de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6763055675442382, 'precision': 0.7449324324324325, 'recall': 0.5582278481012658, 'f1': 0.638205499276411}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a9d0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment saved to: C:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\experiments\\exp_20251226_221046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\konst\\\\Documents\\\\FoR_dataset\\\\for-norm\\\\for-norm\\\\experiments\\\\exp_20251226_221046'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_experiment(\n",
    "    model=pipeline,\n",
    "    metrics=metrics,\n",
    "    experiment_dir=r\"C:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\experiments\",\n",
    "    model_params=svc_params,\n",
    "    feature_names=feature_names,\n",
    "    metadata_extra=metadata_extra,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21f2fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rows with NaNs: 0\n",
      "Testing rows with NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "train_data_path = r\"c:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\training_features.parquet\"\n",
    "test_data_path= r\"c:\\Users\\konst\\Documents\\FoR_dataset\\for-norm\\for-norm\\testing_features.parquet\"\n",
    "\n",
    "train_df = pd.read_parquet(train_data_path)\n",
    "train_df.dropna(inplace=True)\n",
    "test_df = pd.read_parquet(test_data_path)\n",
    "test_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "rows_with_nas_train = train_df.isna().any(axis=1).sum()\n",
    "rows_with_nas_test = test_df.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"Training rows with NaNs: {rows_with_nas_train}\")\n",
    "print(f\"Testing rows with NaNs: {rows_with_nas_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed317d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_deepfake_py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
