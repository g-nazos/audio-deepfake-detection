{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from utils.audio_utils import get_sample_rate\n",
    "\n",
    "from pathlib import Path\n",
    "from configs.config import DATASET_PATH, ITW_DATASET_PATH, ELEVEN_LABS_DATASET_PATH\n",
    "\n",
    "FFMPEG = \"ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c65af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    filepath, filename, category = args\n",
    "    try:\n",
    "        sample_rate = get_sample_rate(filepath)\n",
    "        return {\"filename\": filename, \"category\": category, \"sample_rate\": sample_rate, \"filepath\": filepath, \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {\"filename\": filename, \"category\": category, \"sample_rate\": \"error\", \"filepath\": filepath, \"error\": str(e)}\n",
    "\n",
    "def analyze_sample_rates(base_path, max_workers=12):\n",
    "    categories = [\"real\", \"fake\"]\n",
    "    tasks = []\n",
    "    \n",
    "    for category in categories:\n",
    "        if Path(os.path.join(base_path, \"training\", category)).is_dir():\n",
    "            folder_path = os.path.join(base_path, \"training\", category)\n",
    "        elif Path(os.path.join(base_path, \"testing\", category)).is_dir():\n",
    "            folder_path = os.path.join(base_path, \"testing\", category)\n",
    "        elif Path(os.path.join(base_path, \"validation\", category)).is_dir():\n",
    "            folder_path = os.path.join(base_path, \"validation\", category)\n",
    "        elif Path(os.path.join(base_path, category)).is_dir():\n",
    "            folder_path = os.path.join(base_path, category)\n",
    "        else:\n",
    "            print(f\"Warning: {base_path} does not contain a {category} directory\")\n",
    "            continue\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: {folder_path} does not exist\")\n",
    "            continue\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        for filename in files:\n",
    "            if not filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg')):\n",
    "                continue\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            tasks.append((filepath, filename, category))\n",
    "        \n",
    "        print(f\"Total files to process: {len(tasks)}\")\n",
    "        print(f\"Found {len(files)} files in {category}\")\n",
    "    \n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_file, task): task for task in tasks}\n",
    "        for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Processing\"):\n",
    "            results.append(future.result())\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59546ccc",
   "metadata": {},
   "source": [
    "**Analyzing FoR Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff8e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_sample_rates(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby([\"category\", \"sample_rate\"]).size().unstack(fill_value=0)\n",
    "print(\"Sample Rate Distribution by Category:\")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total files analyzed: {len(df)}\")\n",
    "print(f\"Unique sample rates found: {df['sample_rate'].nunique()}\")\n",
    "print(f\"\\nSample rates: {sorted(df['sample_rate'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = df[df[\"sample_rate\"] == \"error\"]\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "errors[[\"filename\", \"category\", \"error\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef28f10",
   "metadata": {},
   "source": [
    "**Analyzing In The Wild Audio Deepfake Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itw = analyze_sample_rates(ITW_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_itw.groupby([\"category\", \"sample_rate\"]).size().unstack(fill_value=0)\n",
    "print(\"Sample Rate Distribution by Category:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46582148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total files analyzed: {len(df_itw)}\")\n",
    "print(f\"Unique sample rates found: {df_itw['sample_rate'].nunique()}\")\n",
    "print(f\"\\nSample rates: {sorted(df_itw['sample_rate'].unique())}\")\n",
    "\n",
    "errors = df_itw[df_itw[\"sample_rate\"] == \"error\"]\n",
    "print(f\"Total errors: {len(errors)}\")\n",
    "errors[[\"filename\", \"category\", \"error\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d7a3f",
   "metadata": {},
   "source": [
    "<H3> Trim Silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed3661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/geon9/MSc/audio-deepfake-detection/in-the-wild-audio-deepfake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trimming fake: 100%|██████████| 11816/11816 [00:56<00:00, 209.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "print(ITW_DATASET_PATH)\n",
    "INPUT_DIR  = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild\",\"fake\")\n",
    "OUTPUT_DIR = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed\",\"fake\")\n",
    "MAX_WORKERS = 10\n",
    "\n",
    "def trim_file(args):\n",
    "    in_path, out_path, ffmpeg = args\n",
    "    cmd = [\n",
    "        FFMPEG, \"-y\",\n",
    "        \"-i\", in_path,\n",
    "        \"-af\",\n",
    "        \"silenceremove=\"\n",
    "        \"start_periods=1:start_duration=0.3:start_threshold=-50dB:\"\n",
    "        \"stop_periods=1:stop_duration=0.3:stop_threshold=-50dB\",\n",
    "        out_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "        return None\n",
    "    except subprocess.CalledProcessError:\n",
    "        return os.path.basename(in_path)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(trim_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Trimming fake\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c32242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trimming real: 100%|██████████| 19963/19963 [01:35<00:00, 209.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "INPUT_DIR  = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild\",\"real\")\n",
    "OUTPUT_DIR = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed\",\"real\")\n",
    "MAX_WORKERS = 10\n",
    "\n",
    "def trim_file(args):\n",
    "    in_path, out_path, ffmpeg = args\n",
    "    cmd = [\n",
    "        FFMPEG, \"-y\",\n",
    "        \"-i\", in_path,\n",
    "        \"-af\",\n",
    "        \"silenceremove=\"\n",
    "        \"start_periods=1:start_duration=0.3:start_threshold=-50dB:\"\n",
    "        \"stop_periods=1:stop_duration=0.3:stop_threshold=-50dB\",\n",
    "        out_path\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "        return None\n",
    "    except subprocess.CalledProcessError:\n",
    "        return os.path.basename(in_path)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(trim_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Trimming real\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ef5d6",
   "metadata": {},
   "source": [
    "<H3> Loudness Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ed2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing fake: 100%|██████████| 11816/11816 [01:05<00:00, 181.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "INPUT_DIR  = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed\",\"fake\")\n",
    "OUTPUT_DIR = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed_normalized\",\"fake\")\n",
    "MAX_WORKERS = 23\n",
    "\n",
    "TARGET_LUFS = -16\n",
    "TRUE_PEAK   = -1.5\n",
    "# ------------------------\n",
    "\n",
    "def normalize_file(args):\n",
    "    in_path, out_path, ffmpeg, target_lufs, true_peak = args\n",
    "    cmd = [\n",
    "        ffmpeg,\n",
    "        \"-y\",\n",
    "        \"-i\", in_path,\n",
    "        \"-filter:a\",\n",
    "        f\"loudnorm=I={target_lufs}:TP={true_peak}\",\n",
    "        out_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "        return None\n",
    "    except subprocess.CalledProcessError:\n",
    "        return os.path.basename(in_path)\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG, TARGET_LUFS, TRUE_PEAK))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(normalize_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Normalizing fake\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a0a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normalizing real: 100%|██████████| 19963/19963 [02:50<00:00, 116.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------- CONFIG --------\n",
    "INPUT_DIR  = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed\",\"real\")\n",
    "OUTPUT_DIR = os.path.join(ITW_DATASET_PATH, \"release_in_the_wild_trimmed_normalized\", \"real\")\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "TARGET_LUFS = -16\n",
    "TRUE_PEAK   = -1.5\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG, TARGET_LUFS, TRUE_PEAK))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(normalize_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Normalizing real\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f9794",
   "metadata": {},
   "source": [
    "### Eleven labs audio files preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8351f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG --------\n",
    "INPUT_DIR  = os.path.join(ELEVEN_LABS_DATASET_PATH, \"fake\")\n",
    "OUTPUT_DIR = os.path.join(ELEVEN_LABS_DATASET_PATH, \"normalized_fake_real\", \"fake\")\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "TARGET_LUFS =  -15.0 \n",
    "TRUE_PEAK   = -1.5\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG, TARGET_LUFS, TRUE_PEAK))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(normalize_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Normalizing real\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG --------\n",
    "INPUT_DIR  = os.path.join(ELEVEN_LABS_DATASET_PATH, \"real\")\n",
    "OUTPUT_DIR = os.path.join(ELEVEN_LABS_DATASET_PATH, \"normalized_real_real\", \"real\")\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "TARGET_LUFS = -18\n",
    "TRUE_PEAK   = -1.5\n",
    "# ------------------------\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "tasks = []\n",
    "for f in os.listdir(INPUT_DIR):\n",
    "    if not f.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "    in_path = os.path.join(INPUT_DIR, f)\n",
    "    out_path = os.path.join(OUTPUT_DIR, f)\n",
    "    tasks.append((in_path, out_path, FFMPEG, TARGET_LUFS, TRUE_PEAK))\n",
    "\n",
    "failed = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(normalize_file, task): task for task in tasks}\n",
    "    for future in tqdm(as_completed(futures), total=len(tasks), desc=\"Normalizing real\"):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            failed.append(result)\n",
    "\n",
    "if failed:\n",
    "    print(f\"Failed to normalize {len(failed)} files: {failed[:5]}{'...' if len(failed) > 5 else ''}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_deepfake_py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
