{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross-Dataset Validation: FoR → In-the-Wild\n",
        "\n",
        "This notebook evaluates the generalization capability of audio deepfake detection models trained on the FoR (Fake or Real) dataset when tested on the In-the-Wild dataset.\n",
        "\n",
        "**Objective**: Assess how well models trained on controlled/synthetic data generalize to real-world deepfake audio samples.\n",
        "\n",
        "## Dataset Overview\n",
        "- **Training Dataset**: FoR (Fake or Real) - controlled dataset with known TTS systems\n",
        "- **Test Dataset**: In-the-Wild - real-world deepfake audio collected from various sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, \n",
        "    roc_curve, \n",
        "    auc,\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from utils.utils import train_and_evaluate_linear_svm\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration and Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FoR Features Directory: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\FoR_dataset\\features\n",
            "In-the-Wild Dataset Directory: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\release_in_the_wild\n",
            "In-the-Wild Metadata: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\modified_meta.csv\n"
          ]
        }
      ],
      "source": [
        "#fake or real dataset features uesd for training\n",
        "FOR_FEATURES_DIR = PROJECT_ROOT / \"FoR_dataset\" / \"features\"\n",
        "\n",
        "#original itw dataset\n",
        "ITW_META_PATH = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"modified_meta.csv\"\n",
        "ITW_DATASET_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"release_in_the_wild\"\n",
        "ITW_FEATURES_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"features\"\n",
        "ITW_FEATURES = ITW_FEATURES_DIR / \"itw_features_40_2048_512_128.parquet\"\n",
        "\n",
        "#loud normalized itw dataset\n",
        "ITW_NORMALIZED_DATASET_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"release_in_the_wild_normalized\"\n",
        "ITW_NORMALIZED_FEATURES_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"normalized_features\"\n",
        "ITW_NORMALIZED_FEATURES = ITW_NORMALIZED_FEATURES_DIR / \"itw_features_40_2048_512_128_loudness_normalized.parquet\"\n",
        "\n",
        "#silence trimmed itw dataset\n",
        "ITW_TRIMMED_DATASET_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"release_in_the_wild_trimmed\"\n",
        "ITW_TRIMMED_FEATURES_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"normalized_features\"\n",
        "ITW_TRIMMED_FEATURES = ITW_TRIMMED_FEATURES_DIR / \"itw_features_40_2048_512_128_trimmed.parquet\"\n",
        "\n",
        "\n",
        "#silence trimmed and loud normalized itw dataset\n",
        "ITW_TRIMMED_NORMALIZED_DATASET_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"release_in_the_wild_trimmed_normalized\"\n",
        "ITW_TRIMMED_NORMALIZED_FEATURES_DIR = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"normalized_features\"\n",
        "ITW_TRIMMED_NORMALIZED_FEATURES = ITW_TRIMMED_NORMALIZED_FEATURES_DIR / \"itw_features_40_2048_512_128_trimmed_loudness_normalized.parquet\"\n",
        "\n",
        "\n",
        "#silence trimmed and loud normalized itw dataset with no mean and different config\n",
        "ITW_TRIMMED_NORMALIZED_DATASET_DIR_NO_MEAN = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"release_in_the_wild_trimmed_normalized\"\n",
        "ITW_TRIMMED_NORMALIZED_FEATURES_DIR_NO_MEAN = PROJECT_ROOT / \"in-the-wild-audio-deepfake\" / \"normalized_features\"\n",
        "ITW_TRIMMED_NORMALIZED_FEATURES_NO_MEAN = ITW_TRIMMED_NORMALIZED_FEATURES_DIR / \"itw_features_20_128_256_128_trimmed_loudness_normalized.parquet\"\n",
        "\n",
        "print(f\"FoR Features Directory: {FOR_FEATURES_DIR}\")\n",
        "print(f\"In-the-Wild Dataset Directory: {ITW_DATASET_DIR}\")\n",
        "print(f\"In-the-Wild Metadata: {ITW_META_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load FoR Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\geon9\\\\MSc\\\\audio-deepfake-detection\\\\FoR_dataset\\\\features\\\\training_features_20_128_256_128.parquet'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFOR_FEATURES_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_features_20_128_256_128.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m train_df.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFoR Training samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\geon9\\MSc\\audio-deepfake-detection\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\geon9\\MSc\\audio-deepfake-detection\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\geon9\\MSc\\audio-deepfake-detection\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\geon9\\MSc\\audio-deepfake-detection\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\geon9\\\\MSc\\\\audio-deepfake-detection\\\\FoR_dataset\\\\features\\\\training_features_20_128_256_128.parquet'"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_parquet(FOR_FEATURES_DIR / \"training_features_mean_20_128_256_128.parquet\")\n",
        "train_df.dropna(inplace=True)\n",
        "\n",
        "print(f\"FoR Training samples: {len(train_df)}\")\n",
        "print(f\"Features: {train_df.shape[1] - 2}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(train_df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_df.drop(columns=[\"label\", \"filename\"])\n",
        "y_train = train_df[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train distribution: {y_train.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Extract Features from In-the-Wild Dataset\n",
        "\n",
        "We need to extract the same features from the In-the-Wild dataset that were used for the FoR dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#set desired itw features path\n",
        "ITW_FEATURES_PATH = ITW_NORMALIZED_FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached features from c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\normalized_features\\itw_features_40_2048_512_128_loudness_normalized.parquet\n",
            "Loaded 31779 samples\n"
          ]
        }
      ],
      "source": [
        "if ITW_NORMALIZED_FEATURES_DIR.exists() and ITW_NORMALIZED_FEATURES.exists():\n",
        "    print(f\"Loading cached features from {ITW_NORMALIZED_FEATURES}\")\n",
        "    itw_df_normalized = pd.read_parquet(ITW_NORMALIZED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_normalized)} samples\")\n",
        "else:\n",
        "    if not ITW_NORMALIZED_FEATURES_DIR.exists():\n",
        "        print(f\"Creating directory {ITW_NORMALIZED_FEATURES_DIR}\")\n",
        "        ITW_NORMALIZED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if not ITW_NORMALIZED_FEATURES.exists():\n",
        "        print(f\"Features not found. Will extract in next cell.\")\n",
        "        itw_df_normalized = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from In-the-Wild dataset...\n",
            "Dataset path: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\release_in_the_wild_trimmed_normalized\n",
            "Using 5 workers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features: 100%|██████████| 31779/31779 [02:21<00:00, 224.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved features to c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\normalized_features\\itw_features_20_128_256_128_trimmed_loudness_normalized.parquet\n"
          ]
        }
      ],
      "source": [
        "if itw_df is None:\n",
        "    from data_preprocessing.feature_extraction import extract_features_from_folder\n",
        "    \n",
        "    N_MFCC = 20\n",
        "    N_FFT = 128\n",
        "    HOP_LENGTH = 256\n",
        "    N_MELS = 128\n",
        "    \n",
        "    feature_config = {\n",
        "        \"rmse\": {},\n",
        "        \"zero_crossing_rate\": {},\n",
        "        \"spectral_centroid\": {},\n",
        "        \"spectral_bandwidth\": {},\n",
        "        \"spectral_flatness\": {},\n",
        "        \"spectral_rolloff\": {},\n",
        "        \"mfcc\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta2\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"pitch_yin\": {\"fmin\": 50, \"fmax\": 300},\n",
        "        \"mel_spectrogram\": {\"n_mels\": N_MELS},\n",
        "    }\n",
        "    \n",
        "    print(\"Extracting features from In-the-Wild dataset...\")\n",
        "    ITW_DATASET_PATH = ITW_TRIMMED_NORMALIZED_DATASET_DIR_NO_MEAN\n",
        "    print(f\"Dataset path: {ITW_DATASET_PATH}\")\n",
        "    \n",
        "    itw_df = extract_features_from_folder(\n",
        "        folder_path=str(ITW_DATASET_PATH),\n",
        "        feature_config=feature_config,\n",
        "        sample_rate=16000,\n",
        "        num_workers=5\n",
        "    )\n",
        "    \n",
        "    itw_df.to_parquet(ITW_FEATURES_PATH, index=False)\n",
        "    print(f\"Saved features to {ITW_FEATURES_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"In-the-Wild samples: {len(itw_df)}\")\n",
        "print(f\"Features: {itw_df.shape[1] - 2}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(itw_df['label'].value_counts())\n",
        "print(f\"\\nMissing values: {itw_df.isna().sum().max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "itw_df_clean = itw_df.dropna()\n",
        "print(f\"Samples after dropping NaN: {len(itw_df_clean)} (dropped {len(itw_df) - len(itw_df_clean)})\")\n",
        "\n",
        "X_test_itw = itw_df_clean.drop(columns=[\"label\", \"filename\"])\n",
        "y_test_itw = itw_df_clean[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "\n",
        "print(f\"\\nX_test_itw shape: {X_test_itw.shape}\")\n",
        "print(f\"y_test_itw distribution: {y_test_itw.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Alignment Check\n",
        "\n",
        "Ensure both datasets have the same features in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = set(X_train.columns)\n",
        "test_features = set(X_test_itw.columns)\n",
        "\n",
        "missing_in_test = train_features - test_features\n",
        "extra_in_test = test_features - train_features\n",
        "\n",
        "print(f\"Features in training set: {len(train_features)}\")\n",
        "print(f\"Features in test set: {len(test_features)}\")\n",
        "print(f\"Missing in test: {missing_in_test}\")\n",
        "print(f\"Extra in test: {extra_in_test}\")\n",
        "\n",
        "common_features = list(train_features & test_features)\n",
        "X_train_aligned = X_train[common_features]\n",
        "X_test_aligned = X_test_itw[common_features]\n",
        "\n",
        "print(f\"\\nAligned feature count: {len(common_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Models on FoR Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Note: The Linear SVM pipeline includes StandardScaler internally.\")\n",
        "print(f\"X_train_aligned shape: {X_train_aligned.shape}\")\n",
        "print(f\"X_test_aligned shape: {X_test_aligned.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "svc_params = {\n",
        "    \"C\": 100,\n",
        "    \"class_weight\": \"balanced\",\n",
        "    \"max_iter\": 20000,\n",
        "    \"random_state\": 42\n",
        "}\n",
        "\n",
        "train_path = str(FOR_FEATURES_DIR / \"training_features_40_2048_512_128.parquet\")\n",
        "test_path = str(FOR_FEATURES_DIR / \"testing_features_40_2048_512_128.parquet\")\n",
        "\n",
        "print(\"Training Linear SVM on FoR dataset...\")\n",
        "pipeline, for_metrics, _, feature_names, metadata_extra = train_and_evaluate_linear_svm(\n",
        "    train_path, test_path, svc_params\n",
        ")\n",
        "\n",
        "print(f\"\\nFoR Test Set Metrics:\")\n",
        "for k, v in for_metrics.items():\n",
        "    print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_models = {\"Linear SVM\": pipeline}\n",
        "print(\"Linear SVM model ready for cross-dataset evaluation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate on In-the-Wild Dataset (Cross-Dataset Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_path = os.path.join(FOR_FEATURES_DIR, \"training_features_40_2048_512_128.parquet\")\n",
        "test_data_path = os.path.join(ITW_FEATURES)\n",
        "\n",
        "df = pd.read_parquet(train_data_path)\n",
        "df_test = pd.read_parquet(test_data_path)\n",
        "#print(df.head())\n",
        "print(df_test.head())\n",
        "print(df_test.shape)\n",
        "#df.shape()\n",
        "\n",
        "svc_params = {\n",
        "            \"C\": 100,\n",
        "            \"class_weight\": \"balanced\",\n",
        "            \"max_iter\": 20000,\n",
        "            \"random_state\": 42\n",
        "        }\n",
        "pipeline, metrics, svc_params, feature_names, metadata_extra = train_and_evaluate_linear_svm(train_data_path, test_data_path, svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Cross-Dataset Validation Results (FoR → In-the-Wild)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model: Linear SVM\")\n",
        "print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
        "print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Recall:    {metrics['recall']:.4f}\")\n",
        "print(f\"F1 Score:  {metrics['f1']:.4f}\")\n",
        "print(f\"AUC-ROC:   {metrics['roc_auc']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "itw_test_df = pd.read_parquet(ITW_FEATURES_PATH)\n",
        "itw_test_df.dropna(inplace=True)\n",
        "X_itw = itw_test_df.drop(columns=[\"label\", \"filename\"], errors=\"ignore\")\n",
        "y_itw = itw_test_df[\"label\"].map({\"real\": 0, \"fake\": 1}).values\n",
        "\n",
        "y_pred_itw = pipeline.predict(X_itw)\n",
        "y_scores_itw = pipeline.decision_function(X_itw)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_itw, y_pred_itw)\n",
        "sns.heatmap(\n",
        "    cm, \n",
        "    annot=True, \n",
        "    fmt='d', \n",
        "    cmap='Blues',\n",
        "    xticklabels=['Real', 'Fake'],\n",
        "    yticklabels=['Real', 'Fake'],\n",
        "    ax=ax\n",
        ")\n",
        "ax.set_title(\"Linear SVM - Cross-Dataset Validation\")\n",
        "ax.set_ylabel('True Label')\n",
        "ax.set_xlabel('Predicted Label')\n",
        "\n",
        "plt.suptitle('Confusion Matrix (FoR → In-the-Wild)', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr_itw, tpr_itw, _ = roc_curve(y_itw, y_scores_itw)\n",
        "roc_auc_itw = auc(fpr_itw, tpr_itw)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_itw, tpr_itw, label=f\"Linear SVM (AUC = {roc_auc_itw:.3f})\", linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curve - Cross-Dataset Validation (FoR → In-the-Wild)', fontsize=14)\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC-ROC']\n",
        "values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1'], metrics['roc_auc']]\n",
        "colors = ['steelblue', 'forestgreen', 'coral', 'darkorange', 'mediumpurple']\n",
        "\n",
        "bars = ax.bar(metric_names, values, color=colors)\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Linear SVM - Cross-Dataset Validation (FoR → In-the-Wild)', fontsize=14)\n",
        "ax.set_ylim([0, 1.1])\n",
        "\n",
        "for bar, val in zip(bars, values):\n",
        "    ax.annotate(f'{val:.3f}',\n",
        "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
        "                xytext=(0, 3),\n",
        "                textcoords=\"offset points\",\n",
        "                ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Baseline Comparison: Same-Dataset Performance\n",
        "\n",
        "Compare cross-dataset performance with same-dataset (FoR test set) performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for_test_path = FOR_FEATURES_DIR / \"testing_features_40_2048_512_128.parquet\"\n",
        "\n",
        "if for_test_path.exists():\n",
        "    test_for_df = pd.read_parquet(for_test_path)\n",
        "    test_for_df.dropna(inplace=True)\n",
        "    \n",
        "    X_test_for = test_for_df.drop(columns=[\"label\", \"filename\"])[common_features]\n",
        "    y_test_for = test_for_df[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "    \n",
        "    print(f\"FoR Test samples: {len(test_for_df)}\")\n",
        "    print(f\"Label distribution: {y_test_for.value_counts().to_dict()}\")\n",
        "else:\n",
        "    print(\"FoR test features not found\")\n",
        "    X_test_for = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "error_df = itw_df_clean.copy()\n",
        "error_df['predicted'] = y_pred_itw\n",
        "error_df['true_label'] = y_itw\n",
        "error_df['correct'] = error_df['predicted'] == error_df['true_label']\n",
        "error_df['score'] = y_scores_itw\n",
        "\n",
        "print(f\"Model: Linear SVM\")\n",
        "print(f\"\\nCorrect predictions: {error_df['correct'].sum()} ({error_df['correct'].mean()*100:.2f}%)\")\n",
        "print(f\"Incorrect predictions: {(~error_df['correct']).sum()} ({(~error_df['correct']).mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "false_positives = error_df[(error_df['true_label'] == 0) & (error_df['predicted'] == 1)]\n",
        "false_negatives = error_df[(error_df['true_label'] == 1) & (error_df['predicted'] == 0)]\n",
        "\n",
        "print(f\"False Positives (Real predicted as Fake): {len(false_positives)}\")\n",
        "print(f\"False Negatives (Fake predicted as Real): {len(false_negatives)}\")\n",
        "\n",
        "print(f\"\\nTop False Positives (highest score):\")\n",
        "print(false_positives.nlargest(5, 'score')[['filename', 'score']].to_string(index=False))\n",
        "\n",
        "print(f\"\\nTop False Negatives (lowest score):\")\n",
        "print(false_negatives.nsmallest(5, 'score')[['filename', 'score']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Re-extract features fot Loudness Normalized In-The-Wild Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cached features from c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\normalized_features\\itw_features_40_2048_512_128_loudness_normalized.parquet\n",
            "Loaded 31779 samples\n"
          ]
        }
      ],
      "source": [
        "if ITW_NORMALIZED_FEATURES_DIR.exists() and ITW_NORMALIZED_FEATURES.exists():\n",
        "    print(f\"Loading cached features from {ITW_NORMALIZED_FEATURES}\")\n",
        "    itw_df_normalized = pd.read_parquet(ITW_NORMALIZED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_normalized)} samples\")\n",
        "else:\n",
        "    if not ITW_NORMALIZED_FEATURES_DIR.exists():\n",
        "        print(f\"Creating directory {ITW_NORMALIZED_FEATURES_DIR}\")\n",
        "        ITW_NORMALIZED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if not ITW_NORMALIZED_FEATURES.exists():\n",
        "        print(f\"Features not found. Will extract in next cell.\")\n",
        "        itw_df_normalized = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if itw_df_normalized is None and not ITW_NORMALIZED_FEATURES.exists():\n",
        "    from data_preprocessing.feature_extraction import extract_features_from_folder\n",
        "    \n",
        "    N_MFCC = 40\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "    N_MELS = 128\n",
        "    \n",
        "    feature_config = {\n",
        "        \"rmse\": {},\n",
        "        \"zero_crossing_rate\": {},\n",
        "        \"spectral_centroid\": {},\n",
        "        \"spectral_bandwidth\": {},\n",
        "        \"spectral_flatness\": {},\n",
        "        \"spectral_rolloff\": {},\n",
        "        \"mfcc\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta2\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"pitch_yin\": {\"fmin\": 50, \"fmax\": 300},\n",
        "        \"mel_spectrogram\": {\"n_mels\": N_MELS},\n",
        "    }\n",
        "    \n",
        "    print(\"Extracting features from In-the-Wild dataset...\")\n",
        "    print(f\"Dataset path: {ITW_NORMALIZED_DATASET_DIR}\")\n",
        "    \n",
        "    itw_df_normalized = extract_features_from_folder(\n",
        "        folder_path=str(ITW_NORMALIZED_DATASET_DIR),\n",
        "        feature_config=feature_config,\n",
        "        sample_rate=16000,\n",
        "        num_workers=5\n",
        "    )\n",
        "    \n",
        "    itw_df_normalized.to_parquet(ITW_NORMALIZED_FEATURES, index=False)\n",
        "    print(f\"Saved features to {ITW_NORMALIZED_FEATURES}\")\n",
        "else:\n",
        "    print(f\"Loading cached features from {ITW_NORMALIZED_FEATURES}\")\n",
        "    itw_df_normalized = pd.read_parquet(ITW_NORMALIZED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_normalized)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "itw_df_normalized_clean = itw_df_normalized.dropna()\n",
        "print(f\"Samples after dropping NaN: {len(itw_df_normalized_clean)} (dropped {len(itw_df_normalized) - len(itw_df_normalized_clean)})\")\n",
        "\n",
        "X_test_itw_normalized = itw_df_normalized_clean.drop(columns=[\"label\", \"filename\"])\n",
        "y_test_itw_normalized = itw_df_normalized_clean[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "\n",
        "print(f\"\\nX_test_itw_normalized shape: {X_test_itw_normalized.shape}\")\n",
        "print(f\"y_test_itw_normalized distribution: {y_test_itw_normalized.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = set(X_train.columns)\n",
        "test_features = set(X_test_itw_normalized.columns)\n",
        "\n",
        "missing_in_test = train_features - test_features\n",
        "extra_in_test = test_features - train_features\n",
        "\n",
        "print(f\"Features in training set: {len(train_features)}\")\n",
        "print(f\"Features in test set: {len(test_features)}\")\n",
        "print(f\"Missing in test: {missing_in_test}\")\n",
        "print(f\"Extra in test: {extra_in_test}\")\n",
        "\n",
        "common_features = list(train_features & test_features)\n",
        "X_train_aligned = X_train[common_features]\n",
        "X_test_aligned = X_test_itw_normalized[common_features]\n",
        "\n",
        "print(f\"\\nAligned feature count: {len(common_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_path = os.path.join(FOR_FEATURES_DIR, \"training_features_40_2048_512_128.parquet\")\n",
        "test_data_path = os.path.join(ITW_NORMALIZED_FEATURES)\n",
        "\n",
        "df = pd.read_parquet(train_data_path)\n",
        "df_test = pd.read_parquet(test_data_path)\n",
        "#print(df.head())\n",
        "print(df_test.head())\n",
        "print(df_test.shape)\n",
        "#df.shape()\n",
        "\n",
        "svc_params = {\n",
        "            \"C\": 100,\n",
        "            \"class_weight\": \"balanced\",\n",
        "            \"max_iter\": 20000,\n",
        "            \"random_state\": 42\n",
        "        }\n",
        "pipeline, metrics, svc_params, feature_names, metadata_extra = train_and_evaluate_linear_svm(train_data_path, test_data_path, svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Re-extract features for Trimmed Silence In-The-Wild Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ITW_TRIMMED_FEATURES_DIR.exists() and ITW_TRIMMED_FEATURES.exists():\n",
        "    print(f\"Loading cached features from {ITW_TRIMMED_FEATURES}\")\n",
        "    itw_df_trimmed = pd.read_parquet(ITW_TRIMMED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_trimmed)} samples\")\n",
        "else:\n",
        "    if not ITW_TRIMMED_FEATURES_DIR.exists():\n",
        "        print(f\"Creating directory {ITW_TRIMMED_FEATURES_DIR}\")\n",
        "        ITW_TRIMMED_FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if not ITW_TRIMMED_FEATURES.exists():\n",
        "        print(f\"Features not found. Will extract in next cell.\")\n",
        "        itw_df_trimmed = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from In-the-Wild dataset...\n",
            "Dataset path: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\release_in_the_wild_trimmed\n",
            "Using 23 workers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features: 100%|██████████| 31779/31779 [01:43<00:00, 307.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved features to c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\normalized_features\\itw_features_40_2048_512_128_trimmed.parquet\n"
          ]
        }
      ],
      "source": [
        "if itw_df_trimmed is None and not ITW_TRIMMED_FEATURES.exists():\n",
        "    from data_preprocessing.feature_extraction import extract_features_from_folder\n",
        "    \n",
        "    N_MFCC = 40\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "    N_MELS = 128\n",
        "    \n",
        "    feature_config = {\n",
        "        \"rmse\": {},\n",
        "        \"zero_crossing_rate\": {},\n",
        "        \"spectral_centroid\": {},\n",
        "        \"spectral_bandwidth\": {},\n",
        "        \"spectral_flatness\": {},\n",
        "        \"spectral_rolloff\": {},\n",
        "        \"mfcc\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta2\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"pitch_yin\": {\"fmin\": 50, \"fmax\": 300},\n",
        "        \"mel_spectrogram\": {\"n_mels\": N_MELS},\n",
        "    }\n",
        "    \n",
        "    print(\"Extracting features from In-the-Wild dataset...\")\n",
        "    print(f\"Dataset path: {ITW_TRIMMED_DATASET_DIR}\")\n",
        "    \n",
        "    itw_df_trimmed = extract_features_from_folder(\n",
        "        folder_path=str(ITW_TRIMMED_DATASET_DIR),\n",
        "        feature_config=feature_config,\n",
        "        sample_rate=16000,\n",
        "        num_workers=None\n",
        "    )\n",
        "    \n",
        "    itw_df_trimmed.to_parquet(ITW_TRIMMED_FEATURES, index=False)\n",
        "    print(f\"Saved features to {ITW_TRIMMED_FEATURES}\")\n",
        "else:\n",
        "    print(f\"Loading cached features from {ITW_TRIMMED_FEATURES}\")\n",
        "    itw_df_trimmed = pd.read_parquet(ITW_TRIMMED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_trimmed)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "itw_df_trimmed_clean = itw_df_trimmed.dropna()\n",
        "print(f\"Samples after dropping NaN: {len(itw_df_trimmed_clean)} (dropped {len(itw_df_trimmed) - len(itw_df_trimmed_clean)})\")\n",
        "\n",
        "X_test_itw_trimmed = itw_df_trimmed_clean.drop(columns=[\"label\", \"filename\"])\n",
        "y_test_itw_trimmed = itw_df_trimmed_clean[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "\n",
        "print(f\"\\nX_test_itw_trimmed shape: {X_test_itw_trimmed.shape}\")\n",
        "print(f\"y_test_itw_trimmed distribution: {y_test_itw_trimmed.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = set(X_train.columns)\n",
        "test_features = set(X_test_itw_trimmed.columns)\n",
        "\n",
        "missing_in_test = train_features - test_features\n",
        "extra_in_test = test_features - train_features\n",
        "\n",
        "print(f\"Features in training set: {len(train_features)}\")\n",
        "print(f\"Features in test set: {len(test_features)}\")\n",
        "print(f\"Missing in test: {missing_in_test}\")\n",
        "print(f\"Extra in test: {extra_in_test}\")\n",
        "\n",
        "common_features = list(train_features & test_features)\n",
        "X_train_aligned = X_train[common_features]\n",
        "X_test_aligned = X_test_itw_trimmed[common_features]\n",
        "\n",
        "print(f\"\\nAligned feature count: {len(common_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  label   filename  mfcc_mean_0  mfcc_std_0  mfcc_mean_1  mfcc_std_1  \\\n",
            "0  real    100.wav  -194.060593   59.522217    92.874870   36.978516   \n",
            "1  real   1000.wav  -409.435333   92.160080   102.045868   54.739365   \n",
            "2  real  10001.wav  -275.553925   88.372208    85.472183   47.544376   \n",
            "3  real  10003.wav  -408.774170   92.514168   153.550095   30.752758   \n",
            "4  real  10004.wav  -315.357819  108.508636    97.408119   67.490761   \n",
            "\n",
            "   mfcc_mean_2  mfcc_std_2  mfcc_mean_3  mfcc_std_3  ...  \\\n",
            "0   -16.974052   43.922073    28.749113   31.790537  ...   \n",
            "1     3.808117   33.426067    13.269380   32.298374  ...   \n",
            "2   -11.114737   30.097361    -3.776425   27.965250  ...   \n",
            "3     3.010990   15.028880    11.507483   13.281430  ...   \n",
            "4    -1.837851   29.000122    28.668243   25.292135  ...   \n",
            "\n",
            "   mel_spectrogram_mean_123  mel_spectrogram_std_123  \\\n",
            "0                  0.008237                 0.019864   \n",
            "1                  0.000216                 0.000533   \n",
            "2                  0.004186                 0.013382   \n",
            "3                  0.000004                 0.000008   \n",
            "4                  0.000140                 0.000542   \n",
            "\n",
            "   mel_spectrogram_mean_124  mel_spectrogram_std_124  \\\n",
            "0                  0.007992                 0.019883   \n",
            "1                  0.000183                 0.000469   \n",
            "2                  0.003685                 0.013527   \n",
            "3                  0.000002                 0.000004   \n",
            "4                  0.000103                 0.000335   \n",
            "\n",
            "   mel_spectrogram_mean_125  mel_spectrogram_std_125  \\\n",
            "0                  0.005900                 0.016211   \n",
            "1                  0.000096                 0.000239   \n",
            "2                  0.001531                 0.005356   \n",
            "3                  0.000002                 0.000003   \n",
            "4                  0.000057                 0.000166   \n",
            "\n",
            "   mel_spectrogram_mean_126  mel_spectrogram_std_126  \\\n",
            "0                  0.001534                 0.003797   \n",
            "1                  0.000018                 0.000044   \n",
            "2                  0.000244                 0.000671   \n",
            "3                  0.000001                 0.000004   \n",
            "4                  0.000012                 0.000032   \n",
            "\n",
            "   mel_spectrogram_mean_127  mel_spectrogram_std_127  \n",
            "0              1.462104e-04                 0.000411  \n",
            "1              1.696670e-06                 0.000004  \n",
            "2              2.070109e-05                 0.000076  \n",
            "3              8.852837e-07                 0.000004  \n",
            "4              8.012616e-07                 0.000002  \n",
            "\n",
            "[5 rows x 512 columns]\n",
            "(31779, 512)\n"
          ]
        }
      ],
      "source": [
        "train_data_path = os.path.join(FOR_FEATURES_DIR, \"training_features_40_2048_512_128.parquet\")\n",
        "test_data_path = os.path.join(ITW_TRIMMED_FEATURES)\n",
        "\n",
        "df = pd.read_parquet(train_data_path)\n",
        "df_test = pd.read_parquet(test_data_path)\n",
        "#print(df.head())\n",
        "print(df_test.head())\n",
        "print(df_test.shape)\n",
        "#df.shape()\n",
        "\n",
        "svc_params = {\n",
        "            \"C\": 100,\n",
        "            \"class_weight\": \"balanced\",\n",
        "            \"max_iter\": 20000,\n",
        "            \"random_state\": 42\n",
        "        }\n",
        "pipeline, metrics, svc_params, feature_names, metadata_extra = train_and_evaluate_linear_svm(train_data_path, test_data_path, svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.670910187625004, 'precision': 0.6441542542338299, 'recall': 0.2680193564818745, 'f1': 0.5773682440118115, 'roc_auc': 0.5897906113038175}\n"
          ]
        }
      ],
      "source": [
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Re-extract features for Trimmed Silence Loudness Normalized In-The-Wild Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features not found. Will extract in next cell.\n"
          ]
        }
      ],
      "source": [
        "if ITW_TRIMMED_NORMALIZED_DATASET_DIR.exists() and ITW_TRIMMED_NORMALIZED_FEATURES.exists():\n",
        "    print(f\"Loading cached features from {ITW_TRIMMED_NORMALIZED_FEATURES}\")\n",
        "    itw_df_trimmed_normalized = pd.read_parquet(ITW_TRIMMED_NORMALIZED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_trimmed)} samples\")\n",
        "else:\n",
        "    if not ITW_TRIMMED_NORMALIZED_DATASET_DIR.exists():\n",
        "        print(f\"Creating directory {ITW_TRIMMED_NORMALIZED_DATASET_DIR}\")\n",
        "        ITW_TRIMMED_NORMALIZED_DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if not ITW_TRIMMED_NORMALIZED_FEATURES.exists():\n",
        "        print(f\"Features not found. Will extract in next cell.\")\n",
        "        itw_df_trimmed_normalized = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from In-the-Wild dataset...\n",
            "Dataset path: c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\release_in_the_wild_trimmed_normalized\n",
            "Using 23 workers...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting features: 100%|██████████| 31779/31779 [02:03<00:00, 257.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved features to c:\\Users\\geon9\\MSc\\audio-deepfake-detection\\in-the-wild-audio-deepfake\\normalized_features\\itw_features_40_2048_512_128_trimmed_loudness_normalized.parquet\n"
          ]
        }
      ],
      "source": [
        "if itw_df_trimmed_normalized is None and not ITW_TRIMMED_NORMALIZED_FEATURES.exists():\n",
        "    from data_preprocessing.feature_extraction import extract_features_from_folder\n",
        "    \n",
        "    N_MFCC = 40\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "    N_MELS = 128\n",
        "    \n",
        "    feature_config = {\n",
        "        \"rmse\": {},\n",
        "        \"zero_crossing_rate\": {},\n",
        "        \"spectral_centroid\": {},\n",
        "        \"spectral_bandwidth\": {},\n",
        "        \"spectral_flatness\": {},\n",
        "        \"spectral_rolloff\": {},\n",
        "        \"mfcc\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"mfcc_delta2\": {\"n_mfcc\": N_MFCC, \"n_fft\": N_FFT, \"hop_length\": HOP_LENGTH},\n",
        "        \"pitch_yin\": {\"fmin\": 50, \"fmax\": 300},\n",
        "        \"mel_spectrogram\": {\"n_mels\": N_MELS},\n",
        "    }\n",
        "    \n",
        "    print(\"Extracting features from In-the-Wild dataset...\")\n",
        "    print(f\"Dataset path: {ITW_TRIMMED_NORMALIZED_DATASET_DIR}\")\n",
        "    \n",
        "    itw_df_trimmed_normalized = extract_features_from_folder(\n",
        "        folder_path=str(ITW_TRIMMED_NORMALIZED_DATASET_DIR),\n",
        "        feature_config=feature_config,\n",
        "        sample_rate=16000,\n",
        "        num_workers=None\n",
        "    )\n",
        "    \n",
        "    itw_df_trimmed_normalized.to_parquet(ITW_TRIMMED_NORMALIZED_FEATURES, index=False)\n",
        "    print(f\"Saved features to {ITW_TRIMMED_NORMALIZED_FEATURES}\")\n",
        "else:\n",
        "    print(f\"Loading cached features from {ITW_TRIMMED_NORMALIZED_FEATURES}\")\n",
        "    itw_df_trimmed_normalized = pd.read_parquet(ITW_TRIMMED_NORMALIZED_FEATURES)\n",
        "    print(f\"Loaded {len(itw_df_trimmed_normalized)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "itw_df_trimmed_normalized_clean = itw_df_trimmed_normalized.dropna()\n",
        "print(f\"Samples after dropping NaN: {len(itw_df_trimmed_normalized_clean)} (dropped {len(itw_df_trimmed_normalized) - len(itw_df_trimmed_normalized_clean)})\")\n",
        "\n",
        "X_test_itw_trimmed_normalized = itw_df_trimmed_normalized_clean.drop(columns=[\"label\", \"filename\"])\n",
        "y_test_itw_trimmed_normalized = itw_df_trimmed_normalized_clean[\"label\"].map({\"real\": 0, \"fake\": 1})\n",
        "\n",
        "print(f\"\\nX_test_itw_trimmed_normalized shape: {X_test_itw_trimmed_normalized.shape}\")\n",
        "print(f\"y_test_itw_trimmed_normalized distribution: {y_test_itw_trimmed_normalized.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features = set(X_train.columns)\n",
        "test_features = set(X_test_itw_trimmed_normalized.columns)\n",
        "\n",
        "missing_in_test = train_features - test_features\n",
        "extra_in_test = test_features - train_features\n",
        "\n",
        "print(f\"Features in training set: {len(train_features)}\")\n",
        "print(f\"Features in test set: {len(test_features)}\")\n",
        "print(f\"Missing in test: {missing_in_test}\")\n",
        "print(f\"Extra in test: {extra_in_test}\")\n",
        "\n",
        "common_features = list(train_features & test_features)\n",
        "X_train_aligned = X_train[common_features]\n",
        "X_test_aligned = X_test_itw_trimmed_normalized[common_features]\n",
        "\n",
        "print(f\"\\nAligned feature count: {len(common_features)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  label   filename  mfcc_mean_0  mfcc_std_0  mfcc_mean_1  mfcc_std_1  \\\n",
            "0  real    100.wav  -156.601151   59.341663    94.034180   36.503689   \n",
            "1  real   1000.wav  -279.209595   91.934013   102.445534   54.297623   \n",
            "2  real  10001.wav  -177.487381   85.977005    86.514336   47.363522   \n",
            "3  real  10003.wav  -271.900391   92.171707   154.030838   30.958628   \n",
            "4  real  10004.wav  -210.755768  109.072182    97.891685   67.348640   \n",
            "\n",
            "   mfcc_mean_2  mfcc_std_2  mfcc_mean_3  mfcc_std_3  ...  \\\n",
            "0   -18.125744   43.623184    29.887274   31.707443  ...   \n",
            "1     3.412116   33.465878    13.645151   32.440147  ...   \n",
            "2   -11.831045   29.752623    -2.856759   27.914225  ...   \n",
            "3     2.446726   15.398170    12.026384   13.221119  ...   \n",
            "4    -2.266813   28.922297    29.088736   25.278456  ...   \n",
            "\n",
            "   mel_spectrogram_mean_123  mel_spectrogram_std_123  \\\n",
            "0                  0.017062                 0.041203   \n",
            "1                  0.002931                 0.007223   \n",
            "2                  0.030415                 0.103442   \n",
            "3                  0.000049                 0.000095   \n",
            "4                  0.001122                 0.004131   \n",
            "\n",
            "   mel_spectrogram_mean_124  mel_spectrogram_std_124  \\\n",
            "0                  0.015358                 0.038087   \n",
            "1                  0.002315                 0.005923   \n",
            "2                  0.025711                 0.102742   \n",
            "3                  0.000028                 0.000034   \n",
            "4                  0.000776                 0.002434   \n",
            "\n",
            "   mel_spectrogram_mean_125  mel_spectrogram_std_125  \\\n",
            "0                  0.009852                 0.027207   \n",
            "1                  0.001078                 0.002692   \n",
            "2                  0.009497                 0.036454   \n",
            "3                  0.000019                 0.000030   \n",
            "4                  0.000381                 0.001120   \n",
            "\n",
            "   mel_spectrogram_mean_126  mel_spectrogram_std_126  \\\n",
            "0                  0.001500                 0.003841   \n",
            "1                  0.000108                 0.000252   \n",
            "2                  0.000801                 0.002285   \n",
            "3                  0.000006                 0.000019   \n",
            "4                  0.000050                 0.000133   \n",
            "\n",
            "   mel_spectrogram_mean_127  mel_spectrogram_std_127  \n",
            "0              1.871961e-05                 0.000046  \n",
            "1              2.013226e-06                 0.000006  \n",
            "2              1.669190e-05                 0.000084  \n",
            "3              3.002582e-06                 0.000013  \n",
            "4              4.805279e-07                 0.000001  \n",
            "\n",
            "[5 rows x 512 columns]\n",
            "(31779, 512)\n"
          ]
        }
      ],
      "source": [
        "train_data_path = os.path.join(FOR_FEATURES_DIR, \"training_features_40_2048_512_128.parquet\")\n",
        "test_data_path = os.path.join(ITW_TRIMMED_NORMALIZED_FEATURES)\n",
        "\n",
        "df = pd.read_parquet(train_data_path)\n",
        "df_test = pd.read_parquet(test_data_path)\n",
        "#print(df.head())\n",
        "print(df_test.head())\n",
        "print(df_test.shape)\n",
        "#df.shape()\n",
        "\n",
        "svc_params = {\n",
        "            \"C\": 100,\n",
        "            \"class_weight\": \"balanced\",\n",
        "            \"max_iter\": 20000,\n",
        "            \"random_state\": 42\n",
        "        }\n",
        "pipeline, metrics, svc_params, feature_names, metadata_extra = train_and_evaluate_linear_svm(train_data_path, test_data_path, svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.6885297945966539, 'precision': 0.6889400921658986, 'recall': 0.3046098989727481, 'f1': 0.6046045357066804, 'roc_auc': 0.611229898776435}\n"
          ]
        }
      ],
      "source": [
        "print(metrics)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
